{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ox2-CDXSOal"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "T_OHJNZa4OlN"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QVESjRva-Ls1"
   },
   "outputs": [],
   "source": [
    "os.sys.path.append('/content/gdrive/path/to/module_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jz--oRm-Y8_"
   },
   "outputs": [],
   "source": [
    "os.sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VsbCk5Oe1DI3"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from docopt import docopt\n",
    "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu, SmoothingFunction\n",
    "from nmt import Hypothesis, NMT\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict, Set, Union\n",
    "from tqdm import tqdm\n",
    "from utils import read_corpus, batch_iter\n",
    "from vocab import Vocab, VocabEntry\n",
    "\n",
    "import torch\n",
    "import torch.nn.utils\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pCMEQ-HS-F5W"
   },
   "outputs": [],
   "source": [
    "def evaluate_ppl(model, dev_data, batch_size=32):\n",
    "    \"\"\" Evaluate perplexity on dev sentences\n",
    "    @param model (NMT): NMT Model\n",
    "    @param dev_data (list of (src_sent, tgt_sent)): list of tuples containing source and target sentence\n",
    "    @param batch_size (batch size)\n",
    "    @returns ppl (perplixty on dev sentences)\n",
    "    \"\"\"\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    \n",
    "    cum_loss = 0.\n",
    "    cum_tgt_words = 0.\n",
    "    \n",
    "    # no_grad() signals backend to throw away all gradients\n",
    "    with torch.no_grad():\n",
    "        for src_sents, tgt_sents in batch_iter(dev_data, batch_size):\n",
    "            loss = -model(src_sents, tgt_sents).sum()\n",
    "            \n",
    "            cum_loss += loss.item()\n",
    "            tgt_word_num_to_predict = sum(len(s[1:]) for s in tgt_sents) # omitting leading '<s>'\n",
    "            cum_tgt_words += tgt_word_num_to_predict\n",
    "            \n",
    "        ppl = np.exp(cum_loss / cum_tgt_words)\n",
    "        \n",
    "    if was_training:\n",
    "        model.train()\n",
    "        \n",
    "    return ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Yhv4c505-c-1"
   },
   "outputs": [],
   "source": [
    "def compute_corpus_level_bleu_score(references: List[List[str]], hypotheses: List[Hypothesis]) -> float:\n",
    "    \"\"\" Given decoding results and reference sentences, compute corpus-level BLEU score.\n",
    "    @param references (List[List[str]]): a list of gold-standard reference target sentences\n",
    "    @param hypotheses (List[Hypothesis]): a list of hypotheses, one for each reference\n",
    "    @returns bleu_score: corpus-level BLEU score\n",
    "    \"\"\"\n",
    "    if references[0][0] == '<s>':\n",
    "        references = [ref[1:-1] for ref in references]\n",
    "    bleu_score = corpus_bleu([[ref] for ref in references],\n",
    "                             [hyp.value for hyp in hypotheses])\n",
    "    return bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "wFUinXrm-eus"
   },
   "outputs": [],
   "source": [
    "def train(args: Dict):\n",
    "    \"\"\" Train the NMT Model.\n",
    "    @param args (Dict): args from cmd line\n",
    "    \"\"\"\n",
    "    train_data_src = read_corpus(args['train_src'], source='src')\n",
    "    train_data_tgt = read_corpus(args['train_tgt'], source='tgt')\n",
    "    \n",
    "    dev_data_src = read_corpus(args['dev_src'], source='src')\n",
    "    dev_data_tgt = read_corpus(args['dev_tgt'], source='tgt')\n",
    "    \n",
    "    train_data = list(zip(train_data_src, train_data_tgt))\n",
    "    dev_data = list(zip(dev_data_src, dev_data_tgt))\n",
    "    \n",
    "    train_batch_size = int(args['batch_size'])\n",
    "    clip_grad = float(args['clip_grad'])\n",
    "    valid_niter = int(args['valid_niter'])\n",
    "    log_every = int(args['log_every'])\n",
    "    model_save_path = args['save_to']\n",
    "    \n",
    "    if not os.path.exists(model_save_path):\n",
    "      os.makedirs(model_save_path)\n",
    "\n",
    "    vocab = Vocab.load(args['vocab'])\n",
    "    \n",
    "    #print(\"load model from {}\".format(args['model_path']), file=sys.stderr)\n",
    "    if args['continue_training']:\n",
    "\n",
    "      # checkpoint 를 저장한 directory 의 최근 checkpoint 를 불러옴\n",
    "      # e.g., .bin, .optim\n",
    "      ckpt_file_time = []\n",
    "      optim_file_time = []\n",
    "      for f_name in os.listdir(model_save_path):\n",
    "        if '.bin' not in f_name:\n",
    "          continue\n",
    "\n",
    "        written_time = os.path.getctime(f\"{model_save_path}/{f_name}\")\n",
    "   \n",
    "        if f_name.split('.')[-1] == 'optim':\n",
    "          optim_file_time.append((f_name, written_time))\n",
    "        else:\n",
    "          ckpt_file_time.append((f_name, written_time))\n",
    "\n",
    "      sorted_ckpt = sorted(ckpt_file_time, key=lambda x: x[1], reverse=True)\n",
    "      sorted_optim = sorted(optim_file_time, key=lambda x: x[1], reverse=True)\n",
    "      \n",
    "      recent_ckpt = sorted_ckpt[0][0]\n",
    "      recent_optim = sorted_optim[0][0]\n",
    "      \n",
    "      model = NMT.load(os.path.join(model_save_path, recent_ckpt))\n",
    "\n",
    "      last_train_prefixes = recent_ckpt.split('/')[-1].split('_')\n",
    "      last_train_epoch = int(last_train_prefixes[0])\n",
    "      last_train_iter = int(last_train_prefixes[1])\n",
    "      \n",
    "    else:\n",
    "      model = NMT(embed_size=int(args['embed_size']),\n",
    "                hidden_size=int(args['hidden_size']),\n",
    "                dropout_rate=float(args['dropout']),\n",
    "                vocab=vocab)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    if not args['continue_training']:\n",
    "      uniform_init = float(args['uniform_init'])\n",
    "      if np.abs(uniform_init) > 0.:\n",
    "          print('uniformly initialize parameters [-%f, +%f]' % (uniform_init, uniform_init), file=sys.stderr)\n",
    "          for _, p in model.named_parameters():\n",
    "              nn.init.uniform_(p, -uniform_init, uniform_init)\n",
    "\n",
    "    \n",
    "    vocab_mask = torch.ones(len(vocab.tgt))\n",
    "    vocab_mask[vocab.tgt['<pad>']] = 0\n",
    "\n",
    "    #device = torch.device(\"cuda:0\" if args['--cuda'] else \"cpu\")\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print('use device: %s' % device, file=sys.stderr)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=float(args['lr']))\n",
    "    \n",
    "    if args['continue_training']:\n",
    "      print('restore parameters of the optimizers {}'.format(os.path.join(model_save_path, recent_optim)), file=sys.stderr)\n",
    "      optimizer.load_state_dict(torch.load(os.path.join(model_save_path, recent_optim)))\n",
    "\n",
    "    num_trial = 0\n",
    "    train_iter = patience = cum_loss = report_loss = cum_tgt_words = report_tgt_words = 0\n",
    "    cum_examples = report_examples = epoch = valid_num = 0\n",
    "    hist_valid_scores = []\n",
    "    train_time = begin_time = time.time()\n",
    "    print('begin Maximum Likelihood training')\n",
    "    \n",
    "    if args['continue_training']:\n",
    "      train_iter = last_train_iter\n",
    "      epoch = last_train_epoch - 1\n",
    "\n",
    "    while True:\n",
    "\n",
    "        epoch += 1\n",
    "        \n",
    "        for idx, (src_sents, tgt_sents) in enumerate(batch_iter(train_data, batch_size=train_batch_size, shuffle=True)):   \n",
    "            # src_sents shape: (batch_size,)\n",
    "            # tgt_sents shape: (batch_size,)\n",
    "            \n",
    "            if args['continue_training'] and idx < last_train_iter:\n",
    "              continue\n",
    "            \n",
    "            train_iter += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            batch_size = len(src_sents)\n",
    "            \n",
    "            example_losses = -model(src_sents, tgt_sents)\n",
    "            \n",
    "            \n",
    "            batch_loss = example_losses.sum()\n",
    "            loss = batch_loss / batch_size\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            # clip gradient\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            batch_losses_val = batch_loss.item()\n",
    "            report_loss += batch_losses_val\n",
    "            cum_loss += batch_losses_val\n",
    "            \n",
    "            tgt_words_num_to_predict = sum(len(s[1:]) for s in tgt_sents) # omitting leading '<s>'\n",
    "            report_tgt_words += tgt_words_num_to_predict\n",
    "            cum_tgt_words += tgt_words_num_to_predict\n",
    "            report_examples += batch_size\n",
    "            cum_examples += batch_size\n",
    "            \n",
    "            if train_iter % log_every == 0:\n",
    "                print('epoch %d, iter %d, avg. loss %.2f, avg. ppl %.2f ' \\\n",
    "                      'cum. examples %d, speed %.2f words/sec, time elapsed %.2f sec' % (epoch, train_iter, \n",
    "                                                                                         report_loss / report_examples,\n",
    "                                                                                         math.exp(report_loss / report_tgt_words),\n",
    "                                                                                         cum_examples,\n",
    "                                                                                         report_tgt_words / (time.time() - train_time),\n",
    "                                                                                         time.time() - begin_time),\n",
    "                      file=sys.stderr)\n",
    "                \n",
    "                train_time = time.time()\n",
    "                report_loss = report_tgt_words = report_examples = 0.\n",
    "            \n",
    "            # perform validation\n",
    "            if train_iter % valid_niter == 0:\n",
    "                print('epoch %d, iter %d, cum. loss %.2f, cum. ppl %.2f cum. examples %d' % (epoch, train_iter,\n",
    "                                                                                         cum_loss / cum_examples,\n",
    "                                                                                         np.exp(cum_loss / cum_tgt_words),\n",
    "                                                                                         cum_examples), file=sys.stderr)\n",
    "\n",
    "                cum_loss = cum_examples = cum_tgt_words = 0.\n",
    "                valid_num += 1\n",
    "                \n",
    "                print('begin validation ...', file=sys.stderr)\n",
    "                \n",
    "                # compute dev. ppl and bleu\n",
    "                dev_ppl = evaluate_ppl(model, dev_data, batch_size=128) # dev batch size can be a bit larger\n",
    "                valid_metric = -dev_ppl\n",
    "                \n",
    "                print('validation: iter %d, dev. ppl %f' % (train_iter, dev_ppl), file=sys.stderr)\n",
    "                \n",
    "                is_better = len(hist_valid_scores) == 0 or valid_metric > max(hist_valid_scores)\n",
    "                hist_valid_scores.append(valid_metric)\n",
    "                \n",
    "                if is_better:\n",
    "                    patience = 0\n",
    "                    model_save_dir = os.path.join(model_save_path, f'{epoch}_{train_iter}_model.bin')\n",
    "                    print('save currently the best model to [%s]' % model_save_dir, file=sys.stderr)\n",
    "                    model.save(model_save_dir)\n",
    "                    \n",
    "                    # also save the optimizers' state\n",
    "                    torch.save(optimizer.state_dict(), model_save_dir + '.optim')\n",
    "                elif patience < int(args['patience']):\n",
    "                    patience += 1\n",
    "                    print('hit patience %d' % patience, file=sys.stderr)\n",
    "                    \n",
    "                    if patience == int(args['patience']):\n",
    "                        num_trial += 1\n",
    "                        print('hit #%d trial' % num_trial, file=sys.stderr)\n",
    "                        if num_trial == int(args['max_num_trial']):\n",
    "                            print('early stop!', file=sys.stderr)\n",
    "                            exit(0)\n",
    "                        \n",
    "                        # decay lr, and restore from previously best checkpoint\n",
    "                        lr = optimizer.param_groups[0]['lr'] * float(args['lr_decay'])\n",
    "                        print('load previously best model and decay learning rate to %f' % lr, file=sys.stderr)\n",
    "                        \n",
    "                        # load model\n",
    "                        params = torch.load(model_save_path, map_location=lambda storage, loc: storage)\n",
    "                        model.load_state_dict(params['state_dict'])\n",
    "                        model = model.to(device)\n",
    "                        \n",
    "                        print('restore parameters of the optimizers', file=sys.stderr)\n",
    "                        optimizer.load_state_dict(torch.load(model_save_dir + '.optim'))\n",
    "                        \n",
    "                        # set new lr\n",
    "                        for param_group in optimizer.param_groups:\n",
    "                            param_group['lr'] = lr\n",
    "                        \n",
    "                        # reset patience\n",
    "                        patience = 0\n",
    "                        \n",
    "                    if epoch == int(args['max_epoch']):\n",
    "                        print('reached maximum number of epochs!', file=sys.stderr)\n",
    "                        exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "V4SrHzGI-lUU"
   },
   "outputs": [],
   "source": [
    "args = dict()\n",
    "\n",
    "args['train_src'] = \"/content/gdrive/path/to/data/train.de-en.de.wmixerprep\"\n",
    "args['train_tgt'] = \"/content/gdrive/path/to/data/train.de-en.en.wmixerprep\"\n",
    "args['dev_src'] = \"/content/gdrive/path/to/data/valid.de-en.de\"\n",
    "args['dev_tgt'] = \"/content/gdrive/path/to/data/valid.de-en.en\"\n",
    "args['vocab'] = \"/content/gdrive/path/to/data/vocab.json\"\n",
    "\n",
    "args['seed'] = 0\n",
    "args['batch_size'] = 32\n",
    "args['embed_size'] = 256\n",
    "args['hidden_size'] = 256\n",
    "args['clip_grad'] = 5.0\n",
    "args['log_every'] = 10\n",
    "args['max_epoch'] = 30\n",
    "args['patience'] = 5\n",
    "args['max_num_trial'] = 5\n",
    "args['lr_decay'] = 0.5\n",
    "args['beam_size'] = 5\n",
    "args['lr'] = 0.001\n",
    "args['uniform_init'] = 0.1\n",
    "args['save_to'] = '/content/gdrive/path/to/checkpoint'\n",
    "args['valid_niter'] = 100\n",
    "args['dropout'] = 0.3\n",
    "args['max_decoding_time_step'] = 70\n",
    "args['cuda'] = True\n",
    "args['continue_training'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "iQbdFeC_Gb5S"
   },
   "outputs": [],
   "source": [
    "# seed the random number generators\n",
    "seed = int(args['seed'])\n",
    "torch.manual_seed(seed)\n",
    "if args['cuda']:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed * 13 // 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "122Y40e4HH-J"
   },
   "outputs": [],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JyNnvzKpHPAp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
